group_by(city,room_type) %>%
summarise(avg = mean(availability_30))
#What is the average availability over the next 30 days for each room type /
#house size / neighborhood?
#listings %>%
#group_by(city,room_type,bedrooms,neighbourhood_cleansed) %>%
#summarise(avg = mean(availability_30))
listings %>%
group_by(city,room_type) %>%
summarise(availability_average = mean(availability_30))
listings %>%
group_by(city,bedrooms) %>%
summarise(availability_average = mean(availability_30))
listings %>%
group_by(city,neighbourhood_cleansed) %>%
summarise(availability_average = mean(availability_30))
#What is the average availability over the next 30 days for each room type /
#house size / neighborhood?
#listings %>%
#group_by(city,room_type,bedrooms,neighbourhood_cleansed) %>%
#summarise(avg = mean(availability_30))
listings %>%
group_by(city,room_type) %>%
summarise(availability_average = mean(availability_30))
listings %>%
group_by(city,bedrooms) %>%
summarise(availability_average = mean(availability_30))
listings %>%
filter(!is.na(bedrooms))%>%
group_by(city,bedrooms) %>%
summarise(availability_average = mean(availability_30))
listings %>%
group_by(city,neighbourhood_cleansed) %>%
summarise(availability_average = mean(availability_30))
listings %>%
group_by(city,neighbourhood_cleansed) %>%
summarise(availability_average = mean(availability_30))
listings %>%
group_by(city,neighbourhood_cleansed) %>%
summarise(availability_average = mean(availability_30))
listings %>%
filter(!is.na(bedrooms))%>%
group_by(city,bedrooms) %>%
summarise(availability_average = mean(availability_30))
#What is the average revenue over the next 30 days for each room type /
#house size / neighborhood?
listings %>%
group_by(city,room_type) %>%
summarise(revenue_average = mean(revenue_30))
#What is the average revenue over the next 30 days for each room type /
#house size / neighborhood?
#listings %>%
#group_by(city,room_type,bedrooms,neighbourhood_cleansed) %>%
#summarise(revenue_average = mean(revenue_30))
listings %>%
group_by(city,room_type) %>%
summarise(revenue_average = mean(revenue_30))
listings %>%
group_by(city,bedrooms) %>%
summarise(renenue_average = mean(revenue_30))
listings %>%
filter(!is.na(bedrooms))%>%
group_by(city,bedrooms) %>%
summarise(renenue_average = mean(revenue_30))
listings %>%
group_by(city,neighbourhood_cleansed) %>%
summarise(renenue_average = mean(revenue_30))
#What is the distribution of availability over the next 30 days for each room type
#/ house size / neighborhood?
#city/bedrooms
p <- ggplot(listings%>%filter(!is.na(bedrooms)), aes(city, availability_30))
p + geom_boxplot(aes(colour = bedrooms), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$availabilty_30, c(0.1, 0.9), na.rm = T))
#What is the distribution of availability over the next 30 days for each room type
#/ house size / neighborhood?
#city/room_type
p <- ggplot(listings%>%filter(!is.na(room_type)), aes(city, availability_30))
p + geom_boxplot(aes(colour = room_type), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$availabilty_30, c(0.1, 0.9), na.rm = T))
#city/bedrooms
p <- ggplot(listings%>%filter(!is.na(bedrooms)), aes(city, availability_30))
p + geom_boxplot(aes(colour = bedrooms), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$availabilty_30, c(0.1, 0.9), na.rm = T))
#city/neighbourhood_cleansed
p <- ggplot(listings%>%filter(!is.na(neighbourhood_cleansed)), aes(city, availability_30))
p + geom_boxplot(aes(colour = neighbourhood_cleansed), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$availabilty_30, c(0.1, 0.9), na.rm = T))
#city/neighbourhood_cleansed
p <- ggplot(listings%>%filter(!is.na(neighbourhood_cleansed)), aes(city, availability_30))
p + geom_boxplot(aes(colour = neighbourhood_cleansed), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$availabilty_30, c(0.1, 0.9), na.rm = T))+ coord_flip()
#city/neighbourhood_cleansed
p <- ggplot(listings%>% top_n(10) %>% filter(!is.na(neighbourhood_cleansed)), aes(city, availability_30))
p + geom_boxplot(aes(colour = neighbourhood_cleansed), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$availabilty_30, c(0.1, 0.9), na.rm = T))
#city/neighbourhood_cleansed
p <- ggplot(listings%>% top_n(10), aes(city, availability_30))
p + geom_boxplot(aes(colour = neighbourhood_cleansed), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$availabilty_30, c(0.1, 0.9), na.rm = T))
#city/neighbourhood_cleansed
p <- ggplot(listings%>% top_n(20), aes(city, availability_30))
p + geom_boxplot(aes(colour = neighbourhood_cleansed), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$availabilty_30, c(0.1, 0.9), na.rm = T))
#What is the proportion of each neighborhood?
p<-ggplot(listings%>%top_n(20), aes(x=neighbourhood_cleansed))
p + geom_bar()+facet_wrap(~ city)
#What is the distribution of revenue over the next 30 days for each room type /
#house size / neighborhood?
#city/room_type
p <- ggplot(listings%>%filter(!is.na(room_type)), aes(city, revenue_30))
p + geom_boxplot(aes(colour = room_type), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$revenue_30, c(0.1, 0.9), na.rm = T))
#city/bedrooms
p <- ggplot(listings%>%filter(!is.na(bedrooms)), aes(city, revenue_30))
p + geom_boxplot(aes(colour = bedrooms), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$revenue_30, c(0.1, 0.9), na.rm = T))
#city/neighbourhood_cleansed
p <- ggplot(listings%>% top_n(20), aes(city, revenue_30))
p + geom_boxplot(aes(colour = neighbourhood_cleansed), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$revenue_30, c(0.1, 0.9), na.rm = T))
#city/neighbourhood_cleansed
p <- ggplot(listings, aes(city, revenue_30))
p + geom_boxplot(aes(colour = neighbourhood_cleansed), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$revenue_30, c(0.1, 0.9), na.rm = T))
#city/neighbourhood_cleansed
p <- ggplot(listings%>% top_n(30), aes(city, revenue_30))
p + geom_boxplot(aes(colour = neighbourhood_cleansed), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$revenue_30, c(0.1, 0.9), na.rm = T))
#city/neighbourhood_cleansed
p <- ggplot(listings, aes(city, revenue_30))
p + geom_boxplot(aes(colour = neighbourhood_cleansed), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$revenue_30, c(0.1, 0.9), na.rm = T))
#Compare the distribution of estimated #revenue for the next 30 days of listings
#per each city & for each room type #(room_type).
p <- ggplot(listings, aes(room_type, revenue_30))
p + geom_point(aes(colour = "red"), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$revenue_30, c(0.1, 0.9), na.rm = T))+ facet_wrap(~ city)+ coord_flip()
#Compare the distribution of estimated #revenue for the next 30 days of listings
#per each city & for each room type #(room_type).
p <- ggplot(listings, aes(room_type, revenue_30))
p + geom_point(aes(colour = "red"), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$revenue_30, c(0.1, 0.9), na.rm = T))+ facet_wrap(~ city)
#Compare the distribution of estimated #revenue for the next 30 days of listings
#per each city & for each room type #(room_type).
p <- ggplot(listings, aes(room_type, revenue_30))
p + geom_boxplot(aes(colour = "red"), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$revenue_30, c(0.1, 0.9), na.rm = T))+ facet_wrap(~ city)+ coord_flip()
#Compare the distribution of estimated #availability for the next 30 days of
#listings per each city.
p <- ggplot(listings, aes(city, availability_30))
p + geom_boxplot(aes(colour = "red"), outlier.shape = NA,fill='#A4A4A4', color="darkred") +
scale_y_continuous(limits = quantile(listings$availability_30, c(0.1, 0.9), na.rm = T))
#Compare the distribution of estimated #availability for the next 30 days of
#listings per each city.
p <- ggplot(listings, aes(city, availability_30))
p + geom_boxplot(aes(colour = "red"), outlier.shape = NA,fill='#A4A4A4', color="darkblue") +
scale_y_continuous(limits = quantile(listings$availability_30, c(0.1, 0.9), na.rm = T))
#Compare the distribution of estimated #availability for the next 30 days of
#listings per each city.
p <- ggplot(listings, aes(city, availability_30))
p + geom_boxplot(aes(colour = "red",fill='#A4A4A4', color="darkblue"), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$availability_30, c(0.1, 0.9), na.rm = T))
#Compare the distribution of estimated #availability for the next 30 days of
#listings per each city.
p <- ggplot(listings, aes(city, availability_30))
p + geom_boxplot(aes(colour = "red"), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$availability_30, c(0.1, 0.9), na.rm = T))
#city/neighbourhood_cleansed
p <- ggplot(listings%>% top_n(10), aes(city, availability_30))
p + geom_boxplot(aes(colour = neighbourhood_cleansed), outlier.shape = NA) +
scale_y_continuous(limits = quantile(listings$availabilty_30, c(0.1, 0.9), na.rm = T))
library(dplyr)
library(stringr)
library(ggplot2)
library(data.table)
setwd("C:/Users/user/Documents/ING5/Data Analytics/Projet/Airbnb_Project_Data_Analysis/App")
# a generic function to prepare data for a specific city, data_date
prepare_data <- function(url,country,city,date)
{
tmp <- tempfile()
##
download.file(url,tmp)
# Cleaning listings dataframe
listings <- read.csv(gzfile(tmp))
#head(listings)
## Add Keys: columns country,city and day date
listings$country <- country
listings$city <- city
listings$data_date <- date
#
# ## Select interesting columns
# columns_listings <- c("country","city", "date", "id", "neighbourhood_cleansed",
#                        "latitude", "longitude",
#                       "property_type", "room_type", "accommodates", "bedrooms",
#                       "beds", "price", "minimum_nights",  "maximum_nights")
#
# listings <- listings %>%
#   select(columns_listings) %>%
#    arrange(id)
# # Cleaning calendar dataframe
#
# ## arrange by id and date
# calendar <- calendar %>%
#   arrange(listing_id, date)
#
# ## add day number (starting first day)
# calendar <- calendar %>%
#   group_by(listing_id) %>%
#   mutate(day_nb = row_number()) %>%
#   ungroup()
#
# ## change available column to binary
# calendar <- calendar %>%
#   mutate(available = ifelse(available=="t", 1, 0))
#
# ## clean price column and transform to numeric
# calendar <- calendar %>%
#   mutate(price = str_replace(price, "\\$", ""),
#          adjusted_price = str_replace(adjusted_price, "\\$", ""))
# calendar <- calendar %>%
#   mutate(price = str_replace(price, ",", ""),
#          adjusted_price = str_replace(adjusted_price, ",", ""))
# calendar <- calendar %>%
#   mutate(price = as.numeric(price),
#          adjusted_price = as.numeric(adjusted_price))
# ## calculate estimated revenue for upcoming day
# calendar <- calendar %>%
#   mutate(revenue = price*(1-available))
## calculate availability, price, revenue for next 30, 60 days ... for each listing_id
# calendar <- calendar %>%
#   group_by(listing_id) %>%
#   summarise(availability_30 = sum(available[day_nb<=30], na.rm = TRUE),
#             price_30 = mean(price[day_nb<=30 & available==0], na.rm = TRUE),
#             revenue_30 = sum(revenue[day_nb<=30], na.rm = TRUE),
#   )
# dir.create(file.path("data_cleansed", city, data_date), recursive = TRUE)
#
# #write the cleansed data in csv
# write.csv(listings, file.path("data_cleansed", country,city, data_date, "listings.csv"))
# print(paste0("saving data into ", file.path("data_cleansed", country,city, data_date, "listings.csv")))
#
}
#We get the list of urls
urls_path <- file.path("all_data_urls.csv")
print(paste0("reading data from ", urls_path))
urls_data <- read.csv(urls_path)
#We split the url to add columns to filter later
url_decomposed <- str_split(urls_data$listings_data_url,"/",simplify = TRUE)
urls_data$country <- url_decomposed[,4]
urls_data$city <- url_decomposed[,6]
urls_data$date <- url_decomposed[,7]
#We filter the urls on countries and dates
urls_data <-urls_data %>%
filter(country %in% c("spain","france","italy","belgium")) %>%
arrange(country)
urls_data <-slice_head(urls_data%>%group_by(city), n = 5)
urls_data
#Load data fro selected urls
for(i in 1:nrow(urls_data)){
prepare_data(urls_data[i,]$listings_data_url,"spain","barcelona","2020-09-12")
}
# Clean Environment
#rm(list=ls())
## Once data for multiple cities are prepared
## We can read these data and concatenate them together into one dataframe
# # Reading cleansed data
# cities <- c("malaga", "mallorca", "sevilla")
# data_dates <- c("2020-06-30", "2020-09-19", "2020-06-29")
#
# # We are only interested in data between min_date and max_date
# min_date <- '2020-05-01'
# max_date <- '2020-11-01'
#
# files_paths <- c()
#
# # Read data in cities between min_date and max_date
# for(city in cities){
#   file_dir <- file.path(".", "data_cleansed", city)
#   file_subdirs <- list.dirs(file_dir)
#   file_subdirs <- file_subdirs[-1]
#
#   for(file_subdir in file_subdirs){
#     if(file_subdir < file.path(file_dir, min_date) | file_subdir > file.path(file_dir, max_date)  )
#       file_subdirs = file_subdirs[file_subdirs != file_subdir]
#   }
#   files_paths <- c(files_paths, file_subdirs)
# }
# files_paths <- file.path(files_paths, "listings.csv")
# listings <-
#   do.call(rbind,
#           lapply(files_paths, read.csv, row.names=1))
#
# ## Preprocess
# listings$bedrooms <- ifelse(listings$bedrooms >= 5, "5+", listings$bedrooms)
library(dplyr)
library(stringr)
library(ggplot2)
library(data.table)
setwd("C:/Users/user/Documents/ING5/Data Analytics/Projet/Airbnb_Project_Data_Analysis/App")
# a generic function to prepare data for a specific city, data_date
prepare_data <- function(url,country,city,date)
{
tmp <- tempfile()
##
download.file(url,tmp)
# Cleaning listings dataframe
listings <- read.csv(gzfile(tmp))
#head(listings)
## Add Keys: columns country,city and day date
listings$country <- country
listings$city <- city
listings$data_date <- date
#
# ## Select interesting columns
# columns_listings <- c("country","city", "date", "id", "neighbourhood_cleansed",
#                        "latitude", "longitude",
#                       "property_type", "room_type", "accommodates", "bedrooms",
#                       "beds", "price", "minimum_nights",  "maximum_nights")
#
# listings <- listings %>%
#   select(columns_listings) %>%
#    arrange(id)
# # Cleaning calendar dataframe
#
# ## arrange by id and date
# calendar <- calendar %>%
#   arrange(listing_id, date)
#
# ## add day number (starting first day)
# calendar <- calendar %>%
#   group_by(listing_id) %>%
#   mutate(day_nb = row_number()) %>%
#   ungroup()
#
# ## change available column to binary
# calendar <- calendar %>%
#   mutate(available = ifelse(available=="t", 1, 0))
#
# ## clean price column and transform to numeric
# calendar <- calendar %>%
#   mutate(price = str_replace(price, "\\$", ""),
#          adjusted_price = str_replace(adjusted_price, "\\$", ""))
# calendar <- calendar %>%
#   mutate(price = str_replace(price, ",", ""),
#          adjusted_price = str_replace(adjusted_price, ",", ""))
# calendar <- calendar %>%
#   mutate(price = as.numeric(price),
#          adjusted_price = as.numeric(adjusted_price))
# ## calculate estimated revenue for upcoming day
# calendar <- calendar %>%
#   mutate(revenue = price*(1-available))
## calculate availability, price, revenue for next 30, 60 days ... for each listing_id
# calendar <- calendar %>%
#   group_by(listing_id) %>%
#   summarise(availability_30 = sum(available[day_nb<=30], na.rm = TRUE),
#             price_30 = mean(price[day_nb<=30 & available==0], na.rm = TRUE),
#             revenue_30 = sum(revenue[day_nb<=30], na.rm = TRUE),
#   )
# dir.create(file.path("data_cleansed", city, data_date), recursive = TRUE)
#
# #write the cleansed data in csv
# write.csv(listings, file.path("data_cleansed", country,city, data_date, "listings.csv"))
# print(paste0("saving data into ", file.path("data_cleansed", country,city, data_date, "listings.csv")))
#
}
#We get the list of urls
urls_path <- file.path("all_data_urls.csv")
print(paste0("reading data from ", urls_path))
urls_data <- read.csv(urls_path)
#We split the url to add columns to filter later
url_decomposed <- str_split(urls_data$listings_data_url,"/",simplify = TRUE)
urls_data$country <- url_decomposed[,4]
urls_data$city <- url_decomposed[,6]
urls_data$date <- url_decomposed[,7]
#We filter the urls on countries and dates
urls_data <-urls_data %>%
filter(country %in% c("spain","france","italy","belgium")) %>%
arrange(country)
urls_data <-slice_head(urls_data%>%group_by(city), n = 5)
urls_data
#Load data fro selected urls
for(i in 1:nrow(urls_data)){
prepare_data(urls_data[i,]$listings_data_url,urls_data[i,]$country,"barcelona","2020-09-12")
}
# Clean Environment
#rm(list=ls())
## Once data for multiple cities are prepared
## We can read these data and concatenate them together into one dataframe
# # Reading cleansed data
# cities <- c("malaga", "mallorca", "sevilla")
# data_dates <- c("2020-06-30", "2020-09-19", "2020-06-29")
#
# # We are only interested in data between min_date and max_date
# min_date <- '2020-05-01'
# max_date <- '2020-11-01'
#
# files_paths <- c()
#
# # Read data in cities between min_date and max_date
# for(city in cities){
#   file_dir <- file.path(".", "data_cleansed", city)
#   file_subdirs <- list.dirs(file_dir)
#   file_subdirs <- file_subdirs[-1]
#
#   for(file_subdir in file_subdirs){
#     if(file_subdir < file.path(file_dir, min_date) | file_subdir > file.path(file_dir, max_date)  )
#       file_subdirs = file_subdirs[file_subdirs != file_subdir]
#   }
#   files_paths <- c(files_paths, file_subdirs)
# }
# files_paths <- file.path(files_paths, "listings.csv")
# listings <-
#   do.call(rbind,
#           lapply(files_paths, read.csv, row.names=1))
#
# ## Preprocess
# listings$bedrooms <- ifelse(listings$bedrooms >= 5, "5+", listings$bedrooms)
library(dplyr)
library(stringr)
library(ggplot2)
library(data.table)
setwd("C:/Users/user/Documents/ING5/Data Analytics/Projet/Airbnb_Project_Data_Analysis/App")
# a generic function to prepare data for a specific city, data_date
prepare_data <- function(url,country,city,date)
{
tmp <- tempfile()
##
download.file(url,tmp)
# Cleaning listings dataframe
listings <- read.csv(gzfile(tmp))
#head(listings)
## Add Keys: columns country,city and day date
listings$country <- country
listings$city <- city
listings$data_date <- date
#
# ## Select interesting columns
columns_listings <- c("country","city", "date", "id", "neighbourhood_cleansed",
"latitude", "longitude",
"property_type", "room_type", "accommodates", "bedrooms",
"beds", "price", "minimum_nights",  "maximum_nights")
listings <- listings %>%
select(columns_listings) %>%
arrange(id)
# # Cleaning calendar dataframe
#
# ## arrange by id and date
# calendar <- calendar %>%
#   arrange(listing_id, date)
#
# ## add day number (starting first day)
# calendar <- calendar %>%
#   group_by(listing_id) %>%
#   mutate(day_nb = row_number()) %>%
#   ungroup()
#
# ## change available column to binary
# calendar <- calendar %>%
#   mutate(available = ifelse(available=="t", 1, 0))
#
# ## clean price column and transform to numeric
# calendar <- calendar %>%
#   mutate(price = str_replace(price, "\\$", ""),
#          adjusted_price = str_replace(adjusted_price, "\\$", ""))
# calendar <- calendar %>%
#   mutate(price = str_replace(price, ",", ""),
#          adjusted_price = str_replace(adjusted_price, ",", ""))
# calendar <- calendar %>%
#   mutate(price = as.numeric(price),
#          adjusted_price = as.numeric(adjusted_price))
# ## calculate estimated revenue for upcoming day
# calendar <- calendar %>%
#   mutate(revenue = price*(1-available))
## calculate availability, price, revenue for next 30, 60 days ... for each listing_id
# calendar <- calendar %>%
#   group_by(listing_id) %>%
#   summarise(availability_30 = sum(available[day_nb<=30], na.rm = TRUE),
#             price_30 = mean(price[day_nb<=30 & available==0], na.rm = TRUE),
#             revenue_30 = sum(revenue[day_nb<=30], na.rm = TRUE),
#   )
# dir.create(file.path("data_cleansed", city, data_date), recursive = TRUE)
#
# #write the cleansed data in csv
# write.csv(listings, file.path("data_cleansed", country,city, data_date, "listings.csv"))
# print(paste0("saving data into ", file.path("data_cleansed", country,city, data_date, "listings.csv")))
#
}
#We get the list of urls
urls_path <- file.path("all_data_urls.csv")
print(paste0("reading data from ", urls_path))
urls_data <- read.csv(urls_path)
#We split the url to add columns to filter later
url_decomposed <- str_split(urls_data$listings_data_url,"/",simplify = TRUE)
urls_data$country <- url_decomposed[,4]
urls_data$city <- url_decomposed[,6]
urls_data$date <- url_decomposed[,7]
#We filter the urls on countries and dates
urls_data <-urls_data %>%
filter(country %in% c("spain","france","italy","belgium")) %>%
arrange(country)
urls_data <-slice_head(urls_data%>%group_by(city), n = 5)
urls_data
#Load data fro selected urls
for(i in 1:nrow(urls_data)){
prepare_data(urls_data[i,]$listings_data_url,urls_data[i,]$country,urls_data[i,]$city,urls_data[i,]$date)
}
# Clean Environment
#rm(list=ls())
## Once data for multiple cities are prepared
## We can read these data and concatenate them together into one dataframe
# # Reading cleansed data
# cities <- c("malaga", "mallorca", "sevilla")
